An abstract Racket virtual machine (not as object-oriented as it sounds)

Racket [cite Racket] (formerly PLT Scheme) is a batteries-included dialect of Scheme [cite Scheme] enhanced with higher-order contracts, modules and units (cf. ML's functors), and [other additions to Scheme]. Racket code is compiled first to bytecode for evaluation by a custom virtual machine, which provides reference behavior for bytecode programs. Bytecode may be transformed into native code by the JIT compiler.

The Racket virtual machine reflects the fact that Racket bytecode is not a sequence of instructions, but a tree of bytecode forms.

The Racket virtual machine has five registers: the /V/ register holds the value of the
most-recently-evaluated expression; the /S/ register represents the machine's stack which
contains values and heap references; the /H/ register represents the machine's heap which
maps names to values and closure records; the /T/ register is the text segment and
contains a table which entries are the bodies of all lambda expressions; finally, the /C/
register represents the machine's control stack, a hybrid stack containing both
expressions and portions of continuation.

Because of the fundamental differences between the Racket virtual machine and the typical CESK machine of Felleisen [cite CESK], abstraction techniques developed for the latter cannot be applied directly (wc indiscriminately? systematically?) to the former. In order to use existing techniques, we first define an equivalent CESK machine.

Our contribution is a CESK machine for Racket bytecode, proved or tested to be equivalent, and an abstract machine derived from that.

\section{Racket Bytecode}

In the process, many of the operations of the Racket virtual machine become meta-operations. For example, the bytecode interpreter of the Racket machine introduces explicit /framepush/ and /framepop/ directives around the evaluation of arguments and other expressions not in tail position. These directives become implicit in the manipulation of the continuation of the CESK machine.

By adopting the stack as defined as our environment, we inherit many operational similarities. However, elements in the stack are referenced by offset, which means we must obey the stack discipline of the virtual machine to preserve correct behavior. Fortunately, this only affects the meta-language and does not require us to alter the bytecode language at all.

A traditional stack maps identifiers to variables, possibly allocated on the heap. In contrast, a values stack maps offsets to values or heap references. While these offsets can serve as identifiers within certain contexts, bytecode operations which alter the size of the stack cause a conceptual renaming. We could tailor our specific analysis to account for this to preserve precision, but we instead decompile the code which performs an equivalent analysis and packages up code for us... We need some assurance that the decompiled code has the same semantics as the original source. How could it not, if we're assured that the bytecode does?


The first step to interpreting a program abstractly is to obtain a program.

Analysis is limited by the information exported by each imported module. This information
is usually grossly inadequate to service a static analyzer. In a way, the concept of a
module (and abstraction) is opposed to the needs of a whole-program analyzer/optimizer.

What is the purpose of abstract interpretation? To approximate program behaviors. We can
make it arbitrarily precise, but never entirely precise--halting undecideability makes
sure of that.

Abstract interpretation can enable optimizations. Dybvig often cites escape analysis.

MLTon is a whole-program analyzer/optimizer used to great effect. It does not appear to be
well-documented (at least formally).

Might et al. \cite{might2010abstracting} abstracted the CEK machine by gradually
transforming it into a CESK machine, storing environment values and continuations (to
remove recursion), and abstracting that. They applied a similar strategy to abstract a
lazy variant of Krivine's machine.

We apply a similar strategy to abstract the Racket virtual machine \cite{racketmachine}.
We first give a brief overview of the machine.



Our goal is a sound and computable approximation of the behavior of the Racket virtual
machine. We focus first on computability.

It is, in general, impossible to decide whether a program has some static property. (Is
that even true? What makes a property static?)

One method to guarantee computability (decidability) is to make the state space finite. We
will look at each register of the machine and determine how to abstract it in order to
accomplish this.

V) There are an infinite number of values. A natural abstraction is not apparent. In its
absence, we must walk the line between expressiveness and tractability. For instance, we
could abstract to types (boolean, number, symbol, procedure, etc.) which would be
tractable but not expressive.

S) There are an infinite number of stacks. The stack is used as an environment; we can
view the performance of stack operations as a transformation of the environment. If we do
not treat this correctly, we will lose a lot of precision. (That goes for all of these
things.)

H) There are an infinite number of heaps (identified up to renaming of bindings). The
treatment of this follows the treatment in other heap- based machines.

T) Since any given program is finite, the text segment is finite.

C) There are an infinite number of control stacks, but an immense amount of exploitable
structure. A naive abstraction would simply destroy information needlessly.

The Racket virtual machine is sufficiently different from the CESK machine to warrant a
specific investigation.

The Racket compiler transforms source forms into bytecode forms, perhaps performing heavy
analysis and optimization in the process. This format is not inherently safe (meaning it
is possible to express invalid bytecode within the grammar). For this reason, bytecode
must be verified before being loaded. At the same time, the Racket compiler is known not
to produce certain forms, and the verifier doesn't know how to verify these forms. Thus,
the purpose of the verifier seems to be to protect against code which will stall the
abstract machine (by leading to a stuck state).

What are some ways we can guarantee termination of a machine? We are looking for ways in which the termination is natural in the sense that we can draw conclusions about the program from it.

One way is to attach a counter to every syntactic lambda. (The program is finite, so there are a finite number of these, stored in the text segment of the program.) Suppose we only allow functions to be called a certain number of times. Better still, suppose we have a global counter that in incremented at each program call.

Let S_n be the set of programs in our language that halt within n steps.

Ok, this is not well-defined. A program is a semantically valid term in the language with no free variables. This means a closed function is a program. There are an infinite number of inputs. Can we define the maximum over an infinite set?

Let S_n_m be the set of programs in which all inputs up to length m halt within n steps.
If a program doesn't take input--if it ignores its input--then the m argument doesn't affect it.

Now, the output of the program includes a flag indicating whether it halted naturally or not.

If we make the store finite, will all programs halt?

(let ([f (lambda (g) (g g))])
  (f f))
  
Omega, duh.

This program only creates one closure at runtime and never stops. The store is finite, but the program doesn't halt. However, since the state space is finite, we can detect cycles, at the analysis will halt. When we detect a cycle, we gain some information about its halting behavior, but not a "conservative approximation". If we detect a cycle, then the program may not halt. If we don't detect a cycle, then the program halts. (?)

Theorem: if an abstract interpretation of a program doesn't contain any cycles, then the actual program will halt.

In other words, if a program doesn't halt, then its abstract interpretation contains a cycle.

There are programs that don't halt that do not duplicate states in the concrete space. Consider a program which does the same thing over and over but grows the stack indefinitely.

(let ([f (lambda (g) (g (g g)))])
  (f f))
  
(f f)
(f (f f))
(f (f (f f)))
replace the first occurrence of (f f) with (f (f f))

I don't think this is true. Let's try the converse.

Theorem: if a program halts, then its abstract interpretation won't contain any cycles.

If a program halts, then its concrete interpretation won't contain any cycles. However, two distinct concrete states could be mapped to the same abstract state. This would introduce a cycle into the interpretation. This is not a bad thing, because abstract interpretation is not a good approach to approximating halting behavior--it's designed to induce halting behavior!

Theorem: The Racket machine control stack can also grow unbounded.
Proof: Mustn't it be able to since 

(let ([f (lambda (g) (g (g g)))])
  (f f))
  
would cause unbounded growth? The control stack can grow in tandem with the data stack since we can get corresponding popframe directives for each argument evaluation. To be rigorous, we should translate the program into bytecode:

to be done

So, even if we bound the store, there are still programs that won't terminate. We need to bound the control (and instruction) stack also.

We simply need to answer this question: how much information can we decidably get from
a program?

Suppose we make a distinction between the context introduced by the runtime and the original terms. This would introduce continuations, and the analysis would be much more standard. I don't like this idea since it's not novel, but it may be necessary in the end.

(V,S,H,T,C)

NEXT STEP: Understand how the machine works, the behavior of some example programs, etc.


define abstract interpretations for the following properties and state the soundness guarantee for each one:

strictness
reachability
escape

First, strictness.

a function f is strict in its argument if f bot = bot. an n-argument function g is strict in its ith argument if g x_1 x_2 ... x_(i-1) bot x_(x+1) ... x_n = bot.

basically, the abstract interpretation is whether the argument is evaluated. if it is always evaluated, the function is strict in that argument. consider

(define (f x)
  (if (read)
      x
      (+ x 1)))

it is evaluated in the second case (is it though?) but not in the first whereas

(define ...)

it's obvious where we're going; we just need to pin down the conditions that an argument is evaluated

The second is reachability which is dead code elimination. Abstract interpretation abstracts values in the language, not terms or expressions. This means we need to be (somewhat) creative to use it to track terms. Here's an example:

(if #t
    (a)
    (b))
    
Since the branch is always true, we can remove the guard. This expression should be transformed to

(a)

Now we know that b is not reachable, so we can get rid of it. Abstract interpretation to do this is possible, if we don't do a collecting interpretation. Instead, the state of the program at a point is the set of reachable states, or something of that nature.

Racket bytecode abstract interpretation

static contract verification
David van Horn
we're looking to discharge contracts
we want flow information for the stack and store...
